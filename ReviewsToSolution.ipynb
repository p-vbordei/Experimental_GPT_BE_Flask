{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture\n",
    "\n",
    "ASIN Input\n",
    "\n",
    "API Reviews - 30 Reviews\n",
    "API Product Info\n",
    "v\n",
    "Template of Product Information and Reviews. \n",
    "v\n",
    "Problem Statement\n",
    "v\n",
    "Atomization Engine\n",
    "v\n",
    "Solutions Engine\n",
    "v\n",
    "Prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import promptlayer\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "\n",
    "import tiktoken\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import PromptLayerChatOpenAI\n",
    "\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "console = Console()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "SERPAPI_API_KEY = os.getenv('SERPAPI_API_KEY')\n",
    "WOLFRAM_ALPHA_APPID = os.getenv('WOLFRAM_ALPHA_APPID')\n",
    "PROMPTLAYER_API_KEY = os.getenv('PROMPTLAYER_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_amazon_reviews(product_id, api_key=\"70201ee0c8ed29661bc6ae00a84341fb\"):\n",
    "    url = f\"https://h-amazon-data-scraper2.p.rapidapi.com/products/{product_id}/reviews\"\n",
    "\n",
    "    querystring = {\"api_key\": api_key}\n",
    "\n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": \"4da31a08e5mshaca05d98a3d9d6ep1fffb1jsn019717508cc8\",\n",
    "        \"X-RapidAPI-Host\": \"h-amazon-data-scraper2.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    json_data = json.loads(response.text)\n",
    "\n",
    "    # Extract the reviews from the JSON data and convert it to a DataFrame\n",
    "    reviews = pd.DataFrame(json_data['reviews'])\n",
    "\n",
    "    # Export reviews to a CSV file\n",
    "    reviews.to_csv(f\"{product_id}_reviews_sample.csv\", index=False)\n",
    "\n",
    "    return reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewsProcessor:\n",
    "    def __init__(self, source, limit=3000):\n",
    "        self.source = source\n",
    "        self.limit = limit\n",
    "\n",
    "    @staticmethod\n",
    "    def num_tokens_from_string(string: str, encoding_name: str = 'cl100k_base') -> int:\n",
    "        encoding = tiktoken.get_encoding(encoding_name)\n",
    "        num_tokens = len(encoding.encode(string))\n",
    "        return num_tokens\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_asin(url):\n",
    "        pattern = r'ASIN=(\\w{10})'\n",
    "        match = re.search(pattern, url)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_review(review):\n",
    "        return re.sub(r'[^a-zA-Z0-9\\s]+', '', review)\n",
    "\n",
    "    def get_data(self):\n",
    "        df = pd.read_csv(self.source)\n",
    "        df['num_tokens'] = df['Body'].apply(self.num_tokens_from_string)\n",
    "        df['asin'] = df['URL'].apply(self.extract_asin)\n",
    "\n",
    "        df['review'] = df.apply(lambda x: x['Body'][:self.limit * 3] if x['num_tokens'] > self.limit else x['Body'], axis=1)\n",
    "        df['review_num_tokens'] = df['review'].apply(self.num_tokens_from_string)\n",
    "        asin = df['asin'].unique()[0]\n",
    "        df = df[['review', 'review_num_tokens']]\n",
    "        return df, asin\n",
    "\n",
    "    def process_reviews(self, df):\n",
    "        df['review'] = df['review'].apply(self.clean_review)\n",
    "        return df\n",
    "\n",
    "    def create_review_dict(self, df: pd.DataFrame, column_name: str, encoding_name: str = 'cl100k_base', max_tokens: int = 3000) -> Dict[int, str]:\n",
    "        review_dict = {}\n",
    "        current_review_str = \"\"\n",
    "        current_token_count = 0\n",
    "        review_index = 0\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            review = row[column_name]\n",
    "            token_count = self.num_tokens_from_string(review)\n",
    "\n",
    "            if current_token_count + token_count <= max_tokens:\n",
    "                if current_review_str:\n",
    "                    current_review_str += \"\\n\\n\"\n",
    "                current_review_str += review\n",
    "                current_token_count += token_count\n",
    "            else:\n",
    "                review_dict[review_index] = current_review_str\n",
    "                review_index += 1\n",
    "                current_review_str = review\n",
    "                current_token_count = token_count\n",
    "\n",
    "        if current_review_str:\n",
    "            review_dict[review_index] = current_review_str\n",
    "\n",
    "        return review_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_clean_text(df_input, column='Assistant Reply', category=None):\n",
    "    # Filter DataFrame by category if category is provided and the category column exists\n",
    "    if category and 'Category' in df_input.columns:\n",
    "        df_input = df_input[df_input['Category'] == category]\n",
    "\n",
    "    # Extract and clean text from specified column\n",
    "    clean_text = []\n",
    "    for i in range(len(df_input)):\n",
    "        text = df_input[column][i]\n",
    "        \n",
    "        # If the text is an AIMessage object, extract content\n",
    "        if hasattr(text, 'content'):\n",
    "            text = text.content\n",
    "        # If the text is a string representation, extract content inside the double quotes\n",
    "        elif text.startswith('content=\"'):\n",
    "            text = text[len('content=\"'):-1]\n",
    "\n",
    "        # Replace '\\\\n' with '\\n' and split the text into snippets\n",
    "        text_snippet = text.replace('\\\\n', '\\n').split('\\n')\n",
    "        for snippet in text_snippet:\n",
    "            # Check if snippet starts with a number followed by a period and a space\n",
    "            if re.match(r'\\d+\\. ', snippet):\n",
    "                cleaned_snippet = snippet.lstrip('0123456789. ').rstrip(',')\n",
    "                if cleaned_snippet:\n",
    "                    clean_text.append(cleaned_snippet)\n",
    "\n",
    "    # Create a new DataFrame with the extracted text\n",
    "    df_clean_output = pd.DataFrame(clean_text, columns=['Text'])\n",
    "    return df_clean_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name = \"cl100k_base\") -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\"):\n",
    "    \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        print(\"Warning: model not found. Using cl100k_base encoding.\")\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    if model == \"gpt-3.5-turbo\":\n",
    "        print(\"Warning: gpt-3.5-turbo may change over time. Returning num tokens assuming gpt-3.5-turbo-0301.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\")\n",
    "    elif model == \"gpt-4\":\n",
    "        print(\"Warning: gpt-4 may change over time. Returning num tokens assuming gpt-4-0314.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-4-0314\")\n",
    "    elif model == \"gpt-3.5-turbo-0301\":\n",
    "        tokens_per_message = 4  # every message follows <|start|>{role/name}\\n{content}<|end|>\\n\n",
    "        tokens_per_name = -1  # if there's a name, the role is omitted\n",
    "    elif model == \"gpt-4-0314\":\n",
    "        tokens_per_message = 3\n",
    "        tokens_per_name = 1\n",
    "    else:\n",
    "        raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not implemented for model {model}. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\")\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(improvements, max_tokens=1500):\n",
    "        \"\"\"\n",
    "    This function takes a list of improvements and groups them into batches. Each batch has a token count\n",
    "    that doesn't exceed the specified max_tokens limit. It returns a list of batches, where each batch is a\n",
    "    list of improvements.\n",
    "    \n",
    "    Args:\n",
    "        improvements (list): A list of improvement texts.\n",
    "        max_tokens (int): The maximum number of tokens allowed per batch.\n",
    "\n",
    "    Returns:\n",
    "        batches (list): A list of lists, where each inner list represents a batch of improvements.\n",
    "    \"\"\"\n",
    "    batches = []\n",
    "    current_batch = []\n",
    "    current_tokens = 0\n",
    "\n",
    "    for imp in improvements:\n",
    "        if isinstance(imp, float) and np.isnan(imp):  # Skip NaN values\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing improvement: {imp}\")  # Add print statement\n",
    "        imp_tokens = num_tokens_from_string(imp, encoding_name=\"cl100k_base\")\n",
    "        if current_tokens + imp_tokens + 1 <= max_tokens:\n",
    "            current_batch.append(imp)\n",
    "            current_tokens += imp_tokens + 1\n",
    "        else:\n",
    "            print(f\"Batch size: {len(current_batch)}, Tokens: {current_tokens}\")  # Print tokens in the current batch\n",
    "            batches.append(current_batch)\n",
    "            current_batch = [imp]\n",
    "            current_tokens = imp_tokens\n",
    "    if current_batch:\n",
    "        print(f\"Batch size: {len(current_batch)}, Tokens: {current_tokens}\")  # Print tokens in the last batch\n",
    "        batches.append(current_batch)\n",
    "\n",
    "    print(f\"Number of batches: {len(batches)}\")  # Print the number of batches\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_problem_statements(problem_statement_file):\n",
    "    # This function reads problem statements from a CSV file and returns them as a list.\n",
    "    print(\"Reading problem statements\")\n",
    "    problem_statements = []\n",
    "    with open(problem_statement_file, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)  # Skip the header row\n",
    "        for row in reader:\n",
    "            problem_statements.append(row[0])\n",
    "    return problem_statements\n",
    "\n",
    "def write_atomized_problem_solution(atomized_problem_solutions):\n",
    "    #: This function writes problem statements and their solutions to a new CSV file.\n",
    "    print(\"Writing atomized problem solutions\")\n",
    "    with open('atomized_solution_statement.csv', 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"Problem Statement\", \"Solution\"])  # Add a header row\n",
    "        for problem, solution in atomized_problem_solutions:\n",
    "            writer.writerow([problem, solution])\n",
    "\n",
    "def generate_openai_solution(prompt, chat, chat_prompt):\n",
    "    # This function generates a solution to a problem using an OpenAI chatbot.\n",
    "    response = chat(prompt)\n",
    "    solution = extract_content(response)\n",
    "    return solution\n",
    "\n",
    "def extract_content(text):\n",
    "    # This function extracts the content from an OpenAI response.\n",
    "    if hasattr(text, 'content'):\n",
    "        return text.content\n",
    "    elif text.startswith('content=\"'):\n",
    "        return text[len('content=\"'):-1]\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atomize_problem_solutions(problem_statement_file, product_description, openai_api_key):\n",
    "    # This function atomizes problem statements and their solutions.\n",
    "    print(\"Atomizing problem solutions\")\n",
    "    atomized_problem_solutions = []\n",
    "    \n",
    "    # Initialize ChatOpenAI instance\n",
    "    chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_key=openai_api_key)\n",
    "\n",
    "    SystemMessage = \"\"\"You are a TRIZ Engineer and your task is to solve the following problem statement using TRIZ. If the problem cannot be solved using common knowledge, don't solve.\"\"\"\n",
    "    system_message_prompt = SystemMessagePromptTemplate.from_template(SystemMessage)\n",
    "\n",
    "    HumanMessage = \"\"\"Problem Statement: {inputProblemStatement}\n",
    "                    Product Description: {inputProductDescription}\"\"\"\n",
    "    human_message_prompt = HumanMessagePromptTemplate.from_template(HumanMessage)\n",
    "\n",
    "    AiMessage = \"\"\"Solution: \"\"\"\n",
    "    ai_message_prompt = AIMessagePromptTemplate.from_template(AiMessage)\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt, ai_message_prompt])\n",
    "    print(\"Prompt: \", chat_prompt.to_messages())\n",
    "    # Read problem statements from file\n",
    "    problem_statements = read_problem_statements(problem_statement_file)\n",
    "    print(\"Read problem statements from file:\", problem_statements)\n",
    "    \n",
    "    # Process each problem statement\n",
    "    for problem_statement in problem_statements:\n",
    "        print(\"Processing problem statement:\", problem_statement)\n",
    "        prompt = chat_prompt.format_prompt(\n",
    "            inputProblemStatement=problem_statement,\n",
    "            inputProductDescription=product_description\n",
    "        ).to_messages()\n",
    "        print(\"Prompt: \", chat_prompt)\n",
    "        # Generate solution using OpenAI API\n",
    "        atomized_solution = generate_openai_solution(prompt, chat, chat_prompt)\n",
    "        print(\"Generated solution:\", atomized_solution)\n",
    "        \n",
    "        # Append problem statement and solution to list\n",
    "        atomized_problem_solutions.append((problem_statement, atomized_solution))\n",
    "    \n",
    "    # Write atomized problem solutions to file\n",
    "    write_atomized_problem_solution(atomized_problem_solutions)\n",
    "    print(\"Atomized problem solutions written to file\")\n",
    "    \n",
    "    return atomized_problem_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the functions\n",
    "reviews = get_amazon_reviews(\"B08TVXQ5S1\")\n",
    "source = (\"B07ZKTBGR2 - Blinger Ultimate Set, Glam Collection, Comes with  2023-03-16.csv\")\n",
    "processor = ReviewsProcessor(source)\n",
    "df, asin = processor.get_data()\n",
    "df = processor.process_reviews(df)\n",
    "reviews_dict = processor.create_review_dict(df, column_name='review', encoding_name='cl100k_base', max_tokens=processor.limit)\n",
    "\n",
    "# create a DataFrame from the review_dict\n",
    "df_reviews = pd.DataFrame.from_dict(reviews_dict, orient='index', columns=['review'])\n",
    "\n",
    "# save the DataFrame to a CSV file\n",
    "df_reviews.to_csv('reviews.csv', index_label='id')\n",
    "\n",
    "# Read the reviews, checkpoint\n",
    "reviews = pd.read_csv('reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the agent\n",
    "openai = promptlayer.openai\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_key=OPENAI_API_KEY)\n",
    "querry = {0: \"Write the top traits that customers appreciate the most about the product. Provide a description of each trait. \",\n",
    "          1: \"Write what customers dislike about the product. Provide a description of each trait. \",\n",
    "          2: \"What are the improvements that can be brought to this product? Provide a description of each trait. \"}\n",
    "category = {\n",
    "0: \"appreciate\"\n",
    ",1: \"dislike\"\n",
    ",2: \"improvements\"\n",
    "}\n",
    "\n",
    "SystemMessage = \"\"\"Answer the question based on the context and reviews below. You will answer with bulletpoints and extra clarity as a profesional developer. If the question cannot be answered using the information provided answer with \"I don't know\".\n",
    "\n",
    "Context: You are looking at a product sold on amazon.com. We are a competing product development team. Our scope is to better understand the clients need with our product in order to improve the product. \"\"\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(SystemMessage)\n",
    "\n",
    "HumanMessage = \"\"\"Question:  {inputQuestion}\n",
    "                Reviews: {inputReviews} \"\"\"\n",
    "\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(HumanMessage)\n",
    "\n",
    "AiMessage = \"\"\"Answer: \"\"\"\n",
    "ai_message_prompt = AIMessagePromptTemplate.from_template(AiMessage)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt, ai_message_prompt])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"From the reviews provided, it is difficult to determine the top traits that customers appreciate the most about a product. However, some potential traits that customers appreciate are:\\n\\n- Easy to use\\n- Gems stick well to hair and skin\\n- Fun and cute addition to outfits and accessories\\n- Wide variety of gems\\n- Good gift for young girls\\n- Can be used on multiple surfaces (hair, clothes, books, phone cases, etc.)\\n- Can be removed easily without causing damage or discomfort\\n\\nAdditionally, some points of improvement mentioned are:\\n\\n- Adhesive doesn't last very long\\n- Some gems are small and don't work very well with the product\\n- Packaging and/or delivery was not satisfactory in some cases\\n- Product can be messy or difficult to use in some situations\\n- Product may not work well or could be a waste of money in some cases\" additional_kwargs={}\n",
      "content=\"Traits that customers appreciate the least based on the reviews are: \\n\\n- Difficult to use/Operational Issues: A few customers stated that the directions for use were not clear, and the mechanism to put the gems into hair didn't work, leaving them disappointed with the product. Some complained that the product didn't stick to hair for long periods even after trying multiple times. \\n- Inadequate Instructions: Several buyers noted that the instructions were not satisfactory and that they had to watch tutorials online to figure out how to use the product. \\n- Limited functionality: A few customers reported that the adhesive easily comes off, leaving the whole process useless, especially when the product was used on thin surfaces.\\n- Quantity issues: Some customers had complained that the product did not come with enough gems, while a few others reported about missing pieces or getting knockoffs instead of what was described.\\n- Messy: Some reviewers had faced issues of the gems falling off quickly and creating a mess all around.\" additional_kwargs={}\n",
      "content='Based on the reviews, here are the potential improvements that can be brought to this product:\\n- Provide clear instructions on how to use the product.\\n- Ensure that the product matches the pictures shown on the website.\\n- Increase the quality of the product to avoid breaking or malfunctioning.\\n- Improve the adhesiveness of the gems to make them last longer.\\n- Increase the number of gems included in the package.\\n- Decrease the price to make it more accessible to customers.\\n- Improve the refilling process for the gems.\\n- Ensure that the product is eligible for return and provide a refund policy.\\n- Ensure that the product is delivered in good condition.\\n- Avoid using harmful materials that can cause harm or ear infections.\\n- Consider the age range for which the product is designed and make it more suitable for children.\\n- Avoid using materials that can cause sticking to other objects like furniture, bedding, or clothes.' additional_kwargs={}\n",
      "content='After reviewing the reviews, customers appreciate the following traits:\\n\\n1. Easy to use - many customers appreciate that the product is easy to use, and even their younger children can bedazzle their clothes, hair or even their pets. \\n2. Fun - many customers say their children love this product and that it provides joy.\\n3. Sticks well - customers appreciate that the gems are easy to stick and can last long without falling out, especially if clicked perfectly. \\n4. Good value for money - customers appreciate the cost-efficiency of the product and that it can be used over and over again.\\n5. Great for gifting - many customers say this is a perfect product for gifting, especially for little girls who love anything shiny or sparkly. \\n6. Durable - some of the customers say its great for special occasions such as festivals, parties, or weddings. \\n7. Dislikes - Some customers disliked the cheap plastic holder, which can break easily, the product getting stuck or jammed and some found it challenging to use. Other customers found the product overpriced for the number of gems received.' additional_kwargs={}\n",
      "content='There is not enough information to determine the top traits that customers appreciate the least about a product. Most reviews are positive and do not contain any negative aspects of the product.' additional_kwargs={}\n",
      "content=\"Based on the reviews, the improvements that can be brought to this product are:\\n\\n• Increase the number of jewels and refills in the set so that customers can have them for longer use.\\n• Improve the quality and durability of the product so that it is not easily breakable.\\n• Make it easier to use for younger kids by redesigning the machine and the jewel system.\\n• Redesign the package so that it is clear and doesn't mislead customers about the product and what is inside.\\n• Work on the adhesive quality of the gems, so they don't fall out of the hair, and improve its staying power.\" additional_kwargs={}\n"
     ]
    }
   ],
   "source": [
    "df_problem_statement = pd.DataFrame(columns=['Category','Reviews', 'Human Message', 'Assistant Reply'])\n",
    "\n",
    "if len(querry) > 0:\n",
    "    for i in range(len(reviews)):\n",
    "        for j in range(len(querry)):\n",
    "            # PROMPTLAYER\n",
    "            prompt = chat_prompt.format_prompt(\n",
    "                inputQuestion=querry[j],\n",
    "                inputReviews=reviews['review'][i]\n",
    "            ).to_messages()\n",
    "            results = chat(prompt) \n",
    "            print(results)\n",
    "\n",
    "            # create a new dataframe to store the results\n",
    "            df = pd.DataFrame({\n",
    "                'Category': [category[j]],\n",
    "                'Human Message': [querry[j]],\n",
    "                'Assistant Reply': [results],\n",
    "                'Reviews': [reviews['review'][i]]\n",
    "            })\n",
    "            \n",
    "            # add the results to the main dataframe\n",
    "            df_main = pd.concat([df_main, df], ignore_index=True)\n",
    "            \n",
    "df_main.to_csv('questions_and_answers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pd.read_csv('questions_and_answers.csv')\n",
    "improvements_df = extract_clean_improvements(df_main)\n",
    "improvements_df.to_csv('improvements.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing improvement: Based on the reviews, here are the potential improvements that can be brought to this product:\n",
      "Processing improvement: Provide clear instructions on how to use the product.\n",
      "Processing improvement: Ensure that the product matches the pictures shown on the website.\n",
      "Processing improvement: Increase the quality of the product to avoid breaking or malfunctioning.\n",
      "Processing improvement: Improve the adhesiveness of the gems to make them last longer.\n",
      "Processing improvement: Increase the number of gems included in the package.\n",
      "Processing improvement: Decrease the price to make it more accessible to customers.\n",
      "Processing improvement: Improve the refilling process for the gems.\n",
      "Processing improvement: Ensure that the product is eligible for return and provide a refund policy.\n",
      "Processing improvement: Ensure that the product is delivered in good condition.\n",
      "Processing improvement: Avoid using harmful materials that can cause harm or ear infections.\n",
      "Processing improvement: Consider the age range for which the product is designed and make it more suitable for children.\n",
      "Processing improvement: Avoid using materials that can cause sticking to other objects like furniture, bedding, or clothes.\n",
      "Processing improvement: Based on the reviews, the improvements that can be brought to this product are:\n",
      "Processing improvement: \n",
      "Processing improvement: Increase the number of jewels and refills in the set so that customers can have them for longer use.\n",
      "Processing improvement: Improve the quality and durability of the product so that it is not easily breakable.\n",
      "Processing improvement: Make it easier to use for younger kids by redesigning the machine and the jewel system.\n",
      "Processing improvement: Redesign the package so that it is clear and doesn't mislead customers about the product and what is inside.\n",
      "Processing improvement: Work on the adhesive quality of the gems, so they don't fall out of the hair, and improve its staying power.\n",
      "Processing improvement: Based on the reviews, here are the potential improvements that can be brought to this product:\n",
      "Processing improvement: Provide clear instructions on how to use the product\n",
      "Processing improvement: Ensure that the product matches the pictures shown on the website\n",
      "Processing improvement: Increase the quality of the product to avoid breaking or malfunctioning\n",
      "Processing improvement: Improve the adhesiveness of the gems to make them last longer\n",
      "Processing improvement: Increase the number of gems included in the package\n",
      "Processing improvement: Decrease the price to make it more accessible to customers\n",
      "Processing improvement: Improve the refilling process for the gems\n",
      "Processing improvement: Ensure that the product is eligible for return and provide a refund policy\n",
      "Processing improvement: Ensure that the product is delivered in good condition\n",
      "Processing improvement: Avoid using harmful materials that can cause harm or ear infections\n",
      "Processing improvement: Consider the age range for which the product is designed and make it more suitable for children\n",
      "Processing improvement: Avoid using materials that can cause sticking to other objects like furniture, bedding, or clothes\n",
      "Processing improvement: Based on the reviews, the improvements that can be brought to this product are:\n",
      "Processing improvement: Increase the number of jewels and refills in the set so that customers can have them for longer use\n",
      "Processing improvement: Improve the quality and durability of the product so that it is not easily breakable\n",
      "Processing improvement: Make it easier to use for younger kids by redesigning the machine and the jewel system\n",
      "Processing improvement: Redesign the package so that it is clear and doesn't mislead customers about the product and what is inside\n",
      "Processing improvement: Work on the adhesive quality of the gems, so they don't fall out of the hair, and improve its staying power\n",
      "Processing improvement: Based on the reviews, here are the potential improvements that can be brought to this product:\n",
      "Processing improvement: Provide clear instructions on how to use the product\n",
      "Processing improvement: Ensure that the product matches the pictures shown on the website\n",
      "Processing improvement: Increase the quality of the product to avoid breaking or malfunctioning\n",
      "Processing improvement: Improve the adhesiveness of the gems to make them last longer\n",
      "Processing improvement: Increase the number of gems included in the package\n",
      "Processing improvement: Decrease the price to make it more accessible to customers\n",
      "Processing improvement: Improve the refilling process for the gems\n",
      "Processing improvement: Ensure that the product is eligible for return and provide a refund policy\n",
      "Processing improvement: Ensure that the product is delivered in good condition\n",
      "Processing improvement: Avoid using harmful materials that can cause harm or ear infections\n",
      "Processing improvement: Consider the age range for which the product is designed and make it more suitable for children\n",
      "Processing improvement: Avoid using materials that can cause sticking to other objects like furniture, bedding, or clothes\n",
      "Processing improvement: Based on the reviews, the improvements that can be brought to this product are:\n",
      "Processing improvement: Increase the number of jewels and refills in the set so that customers can have them for longer use\n",
      "Processing improvement: Improve the quality and durability of the product so that it is not easily breakable\n",
      "Processing improvement: Make it easier to use for younger kids by redesigning the machine and the jewel system\n",
      "Processing improvement: Redesign the package so that it is clear and doesn't mislead customers about the product and what is inside\n",
      "Processing improvement: Work on the adhesive quality of the gems, so they don't fall out of the hair, and improve its staying power\n",
      "Processing improvement: Based on the reviews, here are the potential improvements that can be brought to this product:\n",
      "Processing improvement: Provide clear instructions on how to use the product.\n",
      "Processing improvement: Ensure that the product matches the pictures shown on the website.\n",
      "Processing improvement: Increase the quality of the product to avoid breaking or malfunctioning.\n",
      "Processing improvement: Improve the adhesiveness of the gems to make them last longer.\n",
      "Processing improvement: Increase the number of gems included in the package.\n",
      "Processing improvement: Decrease the price to make it more accessible to customers.\n",
      "Processing improvement: Improve the refilling process for the gems.\n",
      "Processing improvement: Ensure that the product is eligible for return and provide a refund policy.\n",
      "Processing improvement: Ensure that the product is delivered in good condition.\n",
      "Processing improvement: Avoid using harmful materials that can cause harm or ear infections.\n",
      "Processing improvement: Consider the age range for which the product is designed and make it more suitable for children.\n",
      "Processing improvement: Avoid using materials that can cause sticking to other objects like furniture, bedding, or clothes.\n",
      "Processing improvement: Based on the reviews, the improvements that can be brought to this product are:\n",
      "Processing improvement: Increase the number of jewels and refills in the set so that customers can have them for longer use.\n",
      "Processing improvement: Improve the quality and durability of the product so that it is not easily breakable.\n",
      "Processing improvement: Make it easier to use for younger kids by redesigning the machine and the jewel system.\n",
      "Processing improvement: Redesign the package so that it is clear and doesn't mislead customers about the product and what is inside.\n",
      "Processing improvement: Work on the adhesive quality of the gems, so they don't fall out of the hair, and improve its staying power.\n",
      "Batch size: 77, Tokens: 1215\n",
      "Number of batches: 1\n",
      "Processing improvement: Based on the reviews, here are the potential improvements that can be brought to this product:\n",
      "Processing improvement: Provide clear instructions on how to use the product.\n",
      "Processing improvement: Ensure that the product matches the pictures shown on the website.\n",
      "Processing improvement: Increase the quality of the product to avoid breaking or malfunctioning.\n",
      "Processing improvement: Improve the adhesiveness of the gems to make them last longer.\n",
      "Processing improvement: Increase the number of gems included in the package.\n",
      "Processing improvement: Decrease the price to make it more accessible to customers.\n",
      "Processing improvement: Improve the refilling process for the gems.\n",
      "Processing improvement: Ensure that the product is eligible for return and provide a refund policy.\n",
      "Processing improvement: Ensure that the product is delivered in good condition.\n",
      "Processing improvement: Avoid using harmful materials that can cause harm or ear infections.\n",
      "Processing improvement: Consider the age range for which the product is designed and make it more suitable for children.\n",
      "Processing improvement: Avoid using materials that can cause sticking to other objects like furniture, bedding, or clothes.\n",
      "Processing improvement: Based on the reviews, the improvements that can be brought to this product are:\n",
      "Processing improvement: \n",
      "Processing improvement: Increase the number of jewels and refills in the set so that customers can have them for longer use.\n",
      "Processing improvement: Improve the quality and durability of the product so that it is not easily breakable.\n",
      "Processing improvement: Make it easier to use for younger kids by redesigning the machine and the jewel system.\n",
      "Processing improvement: Redesign the package so that it is clear and doesn't mislead customers about the product and what is inside.\n",
      "Processing improvement: Work on the adhesive quality of the gems, so they don't fall out of the hair, and improve its staying power.\n",
      "Processing improvement: Based on the reviews, here are the potential improvements that can be brought to this product:\n",
      "Processing improvement: Provide clear instructions on how to use the product\n",
      "Processing improvement: Ensure that the product matches the pictures shown on the website\n",
      "Processing improvement: Increase the quality of the product to avoid breaking or malfunctioning\n",
      "Processing improvement: Improve the adhesiveness of the gems to make them last longer\n",
      "Processing improvement: Increase the number of gems included in the package\n",
      "Processing improvement: Decrease the price to make it more accessible to customers\n",
      "Processing improvement: Improve the refilling process for the gems\n",
      "Processing improvement: Ensure that the product is eligible for return and provide a refund policy\n",
      "Processing improvement: Ensure that the product is delivered in good condition\n",
      "Processing improvement: Avoid using harmful materials that can cause harm or ear infections\n",
      "Processing improvement: Consider the age range for which the product is designed and make it more suitable for children\n",
      "Processing improvement: Avoid using materials that can cause sticking to other objects like furniture, bedding, or clothes\n",
      "Processing improvement: Based on the reviews, the improvements that can be brought to this product are:\n",
      "Processing improvement: Increase the number of jewels and refills in the set so that customers can have them for longer use\n",
      "Processing improvement: Improve the quality and durability of the product so that it is not easily breakable\n",
      "Processing improvement: Make it easier to use for younger kids by redesigning the machine and the jewel system\n",
      "Processing improvement: Redesign the package so that it is clear and doesn't mislead customers about the product and what is inside\n",
      "Processing improvement: Work on the adhesive quality of the gems, so they don't fall out of the hair, and improve its staying power\n",
      "Processing improvement: Based on the reviews, here are the potential improvements that can be brought to this product:\n",
      "Processing improvement: Provide clear instructions on how to use the product\n",
      "Processing improvement: Ensure that the product matches the pictures shown on the website\n",
      "Processing improvement: Increase the quality of the product to avoid breaking or malfunctioning\n",
      "Processing improvement: Improve the adhesiveness of the gems to make them last longer\n",
      "Processing improvement: Increase the number of gems included in the package\n",
      "Processing improvement: Decrease the price to make it more accessible to customers\n",
      "Processing improvement: Improve the refilling process for the gems\n",
      "Processing improvement: Ensure that the product is eligible for return and provide a refund policy\n",
      "Processing improvement: Ensure that the product is delivered in good condition\n",
      "Processing improvement: Avoid using harmful materials that can cause harm or ear infections\n",
      "Processing improvement: Consider the age range for which the product is designed and make it more suitable for children\n",
      "Processing improvement: Avoid using materials that can cause sticking to other objects like furniture, bedding, or clothes\n",
      "Processing improvement: Based on the reviews, the improvements that can be brought to this product are:\n",
      "Processing improvement: Increase the number of jewels and refills in the set so that customers can have them for longer use\n",
      "Processing improvement: Improve the quality and durability of the product so that it is not easily breakable\n",
      "Processing improvement: Make it easier to use for younger kids by redesigning the machine and the jewel system\n",
      "Processing improvement: Redesign the package so that it is clear and doesn't mislead customers about the product and what is inside\n",
      "Processing improvement: Work on the adhesive quality of the gems, so they don't fall out of the hair, and improve its staying power\n",
      "Processing improvement: Based on the reviews, here are the potential improvements that can be brought to this product:\n",
      "Processing improvement: Provide clear instructions on how to use the product.\n",
      "Processing improvement: Ensure that the product matches the pictures shown on the website.\n",
      "Processing improvement: Increase the quality of the product to avoid breaking or malfunctioning.\n",
      "Processing improvement: Improve the adhesiveness of the gems to make them last longer.\n",
      "Processing improvement: Increase the number of gems included in the package.\n",
      "Processing improvement: Decrease the price to make it more accessible to customers.\n",
      "Processing improvement: Improve the refilling process for the gems.\n",
      "Processing improvement: Ensure that the product is eligible for return and provide a refund policy.\n",
      "Processing improvement: Ensure that the product is delivered in good condition.\n",
      "Processing improvement: Avoid using harmful materials that can cause harm or ear infections.\n",
      "Processing improvement: Consider the age range for which the product is designed and make it more suitable for children.\n",
      "Processing improvement: Avoid using materials that can cause sticking to other objects like furniture, bedding, or clothes.\n",
      "Processing improvement: Based on the reviews, the improvements that can be brought to this product are:\n",
      "Processing improvement: Increase the number of jewels and refills in the set so that customers can have them for longer use.\n",
      "Processing improvement: Improve the quality and durability of the product so that it is not easily breakable.\n",
      "Processing improvement: Make it easier to use for younger kids by redesigning the machine and the jewel system.\n",
      "Processing improvement: Redesign the package so that it is clear and doesn't mislead customers about the product and what is inside.\n",
      "Processing improvement: Work on the adhesive quality of the gems, so they don't fall out of the hair, and improve its staying power.\n",
      "Batch size: 77, Tokens: 1215\n",
      "Number of batches: 1\n"
     ]
    }
   ],
   "source": [
    "improvements_df = pd.read_csv('improvements.txt')\n",
    "improvements_df['Improvements'] = improvements_df['Improvements'].fillna('')\n",
    "improvement_batches = generate_batches(improvements_df['Improvements'])\n",
    "improvements_filtered = improvements_df['Improvements'].dropna()\n",
    "improvement_batches = generate_batches(improvements_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of improvements_df: 77\n",
      "Length of improvement_batches: 77\n"
     ]
    }
   ],
   "source": [
    "improvements_df_length = len(improvements_df)\n",
    "improvements_batches_length = sum(len(batch) for batch in improvement_batches)\n",
    "\n",
    "print(f\"Length of improvements_df: {improvements_df_length}\")\n",
    "print(f\"Length of improvement_batches: {improvements_batches_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Querry needs to be improved\n",
    "# too much of the problem statement is lost in summarization\n",
    "\n",
    "querry = \"What are the distinct problem statements that can be solved by an engineering team based on the following improvements?\"\n",
    "\n",
    "SystemMessage = \"\"\"Answer the question based on the context and improvements below. You will answer with bulletpoints and extra clarity as a professional developer. If the question cannot be answered using the information provided, answer with \"I don't know\".\n",
    "\n",
    "Context: You are looking at a product sold on amazon.com. We are a competing product development team. Our scope is to better understand the clients' needs with our product in order to improve it. \"\"\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(SystemMessage)\n",
    "\n",
    "HumanMessage = \"\"\"Question:  {inputQuestion}\n",
    "                Improvements: {inputImprovements} \"\"\"\n",
    "\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(HumanMessage)\n",
    "\n",
    "AiMessage = \"\"\"Answer: \"\"\"\n",
    "ai_message_prompt = AIMessagePromptTemplate.from_template(AiMessage)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt, ai_message_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer')).\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39m# PROMPTLAYER\u001b[39;00m\n\u001b[1;32m      7\u001b[0m prompt \u001b[39m=\u001b[39m chat_prompt\u001b[39m.\u001b[39mformat_prompt(\n\u001b[1;32m      8\u001b[0m     inputQuestion\u001b[39m=\u001b[39mquerry,\n\u001b[1;32m      9\u001b[0m     inputImprovements\u001b[39m=\u001b[39mimprovements_text\n\u001b[1;32m     10\u001b[0m )\u001b[39m.\u001b[39mto_messages()\n\u001b[0;32m---> 11\u001b[0m results \u001b[39m=\u001b[39m chat(prompt)\n\u001b[1;32m     12\u001b[0m \u001b[39mprint\u001b[39m(results)\n\u001b[1;32m     14\u001b[0m \u001b[39m# create a new dataframe to store the results\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/oaie/lib/python3.8/site-packages/langchain/chat_models/base.py:128\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[0;34m(self, messages, stop)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m    126\u001b[0m     \u001b[39mself\u001b[39m, messages: List[BaseMessage], stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    127\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BaseMessage:\n\u001b[0;32m--> 128\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(messages, stop\u001b[39m=\u001b[39;49mstop)\u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/anaconda3/envs/oaie/lib/python3.8/site-packages/langchain/chat_models/openai.py:256\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop)\u001b[0m\n\u001b[1;32m    252\u001b[0m     message \u001b[39m=\u001b[39m _convert_dict_to_message(\n\u001b[1;32m    253\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: inner_completion, \u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: role}\n\u001b[1;32m    254\u001b[0m     )\n\u001b[1;32m    255\u001b[0m     \u001b[39mreturn\u001b[39;00m ChatResult(generations\u001b[39m=\u001b[39m[ChatGeneration(message\u001b[39m=\u001b[39mmessage)])\n\u001b[0;32m--> 256\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompletion_with_retry(messages\u001b[39m=\u001b[39;49mmessage_dicts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/anaconda3/envs/oaie/lib/python3.8/site-packages/langchain/chat_models/openai.py:218\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 218\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/oaie/lib/python3.8/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/anaconda3/envs/oaie/lib/python3.8/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/oaie/lib/python3.8/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m~/anaconda3/envs/oaie/lib/python3.8/concurrent/futures/_base.py:437\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    436\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 437\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    439\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    441\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/anaconda3/envs/oaie/lib/python3.8/concurrent/futures/_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    388\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    390\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    392\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/oaie/lib/python3.8/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/oaie/lib/python3.8/site-packages/langchain/chat_models/openai.py:216\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/oaie/lib/python3.8/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/anaconda3/envs/oaie/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/anaconda3/envs/oaie/lib/python3.8/site-packages/openai/api_requestor.py:216\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[1;32m    219\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    220\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    221\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    222\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    223\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[1;32m    226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/anaconda3/envs/oaie/lib/python3.8/site-packages/openai/api_requestor.py:516\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    514\u001b[0m     _thread_context\u001b[39m.\u001b[39msession \u001b[39m=\u001b[39m _make_session()\n\u001b[1;32m    515\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 516\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    517\u001b[0m         method,\n\u001b[1;32m    518\u001b[0m         abs_url,\n\u001b[1;32m    519\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    520\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    521\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    522\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    523\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[1;32m    524\u001b[0m         proxies\u001b[39m=\u001b[39;49m_thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mproxies,\n\u001b[1;32m    525\u001b[0m     )\n\u001b[1;32m    526\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    527\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mTimeout(\u001b[39m\"\u001b[39m\u001b[39mRequest timed out: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/oaie/lib/python3.8/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/oaie/lib/python3.8/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/envs/oaie/lib/python3.8/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    490\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    491\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    492\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    493\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    494\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    496\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    497\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    498\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    499\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    500\u001b[0m         )\n\u001b[1;32m    502\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/oaie/lib/python3.8/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/oaie/lib/python3.8/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/oaie/lib/python3.8/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/oaie/lib/python3.8/http/client.py:1348\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1347\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1349\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1350\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/oaie/lib/python3.8/http/client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    317\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    318\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/oaie/lib/python3.8/http/client.py:277\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 277\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    279\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/oaie/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    670\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/oaie/lib/python3.8/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1242\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/oaie/lib/python3.8/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1100\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_small_problem_statement = pd.DataFrame(columns=['Improvements', 'Assistant Reply'])\n",
    "\n",
    "for batch in improvement_batches:\n",
    "    improvements_text = \"\\n\".join(batch)\n",
    "    \n",
    "    # PROMPTLAYER\n",
    "    prompt = chat_prompt.format_prompt(\n",
    "        inputQuestion=querry,\n",
    "        inputImprovements=improvements_text\n",
    "    ).to_messages()\n",
    "    results = chat(prompt)\n",
    "    print(results)\n",
    "\n",
    "    # create a new dataframe to store the results\n",
    "    df = pd.DataFrame({\n",
    "        'Assistant Reply': [results],\n",
    "        'Improvements': [improvements_text]\n",
    "    })\n",
    "\n",
    "    # add the results to the df_small_problem_statement dataframe\n",
    "    df_small_problem_statement = pd.concat([df_small_problem_statement, df], ignore_index=True)\n",
    "\n",
    "df_small_problem_statement.to_csv('problem_statements.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Text\n",
      "0                          Lack of Clear Instructions\n",
      "1   Product does not match the pictures shown on t...\n",
      "2                          Low Quality and Durability\n",
      "3                                Lack of Adhesiveness\n",
      "4                        Shortage of Gems and Refills\n",
      "5                                          High Price\n",
      "6                               Refill Process Hassle\n",
      "7                               Lack of Return Policy\n",
      "8                                      Poor Packaging\n",
      "9                          Unsuitability for Children\n",
      "10                                  Harmful Materials\n",
      "11                    Utilization of Sticky Materials\n"
     ]
    }
   ],
   "source": [
    "df_small_problem_statement = pd.read_csv('problem_statements.csv')\n",
    "atomized_problem_statement = extract_clean_text(df_small_problem_statement, column='Assistant Reply')\n",
    "print(atomized_problem_statement)\n",
    "atomized_problem_statement.to_csv('atomized_problem_statement.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe this product:\n",
    "# - components\n",
    "# - materials\n",
    "# - how it's used\n",
    "# <Proudct Title> \n",
    "\n",
    "\n",
    "ProductDescription = {\n",
    "\"Name\": \"Blinger Ultimate Set, Glam Collection, Comes with Glam Styling Tool & 225 Gems - Load, Click, Bling! Hair, Fashion, Anything! (Amazon Exclusive)\",\n",
    "\"Bullets\": [\n",
    "\"Blinger Ultimate Set, Glam Collection, Comes with Glam Styling Tool & 225 Gems - Load, Click, BLING. Hair, Fashion, ANYTHING. (Exclusive)\",\n",
    "\"Blinger is the new Glam Styling Tool that allows you to Load, Click, BLING – Hair, Fashion ANYTHING.\",\n",
    "\"With 225 adhesive gems included & multiple colors to choose from, Blinger makes it easy for you to glam it up and add sparkle to your life.\",\n",
    "\"The Blinger Glam Collection is a fashionista’s dream – finally, a styling tool that allows you add all the BLING to your everyday life and create your own striking looks.\",\n",
    "\"It’s totally safe and easy to use, however Blinger is a styling tool and there is always a chance it needs a little tune up or fix. If you experience any issue please contact our customer service and it will be our pleasure to help fix or replace.\"\n",
    "],\n",
    "\"Assistant Intuition\": \"The Blinger Ultimate Set, Glam Collection, is a hair and fashion accessory kit that allows you to add sparkling gems to your hair, clothing, and accessories. The set includes a Glam Styling Tool and 225 gems in various shapes and colors.\\n\\nThe components of the set include the Glam Styling Tool, which is a handheld device that you load with gems and click to apply them to your hair or clothing. The set also includes 225 gems, which come in different shapes such as stars, hearts, and circles, and in various colors like pink, blue, green, and silver.\\n\\nThe materials used in the set include plastic for the Glam Styling Tool and metal and rhinestones for the gems. The gems are made with high-quality materials that are durable and long-lasting.\\n\\nTo use the Blinger Ultimate Set, you load the gems into the Glam Styling Tool and click the button to apply them to your hair or clothing. The set is designed to be used on any type of hair or fabric, making it a versatile accessory that can be used to add some sparkle and glam to any outfit or hairstyle. The Blinger Ultimate Set is an Amazon Exclusive product, which means that it can only be purchased on Amazon's online store.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atomizing problem solutions\n",
      "Reading problem statements\n",
      "Read problem statements from file: ['Text', 'Low Quality and Durability', 'Lack of Adhesiveness', 'Shortage of Gems and Refills', 'High Price']\n",
      "Processing problem statement: Text\n",
      "Prompt:  [SystemMessage(content=\"You are a TRIZ Engineer and your task is to solve the following problem statement using TRIZ. If the problem cannot be solved using common knowledge, don't solve.\", additional_kwargs={}), HumanMessage(content='Problem Statement: Text\\n                    Product Description: {\\'Name\\': \\'Blinger Ultimate Set, Glam Collection, Comes with Glam Styling Tool & 225 Gems - Load, Click, Bling! Hair, Fashion, Anything! (Amazon Exclusive)\\', \\'Bullets\\': [\\'Blinger Ultimate Set, Glam Collection, Comes with Glam Styling Tool & 225 Gems - Load, Click, BLING. Hair, Fashion, ANYTHING. (Exclusive)\\', \\'Blinger is the new Glam Styling Tool that allows you to Load, Click, BLING – Hair, Fashion ANYTHING.\\', \\'With 225 adhesive gems included & multiple colors to choose from, Blinger makes it easy for you to glam it up and add sparkle to your life.\\', \\'The Blinger Glam Collection is a fashionista’s dream – finally, a styling tool that allows you add all the BLING to your everyday life and create your own striking looks.\\', \\'It’s totally safe and easy to use, however Blinger is a styling tool and there is always a chance it needs a little tune up or fix. If you experience any issue please contact our customer service and it will be our pleasure to help fix or replace.\\'], \\'Assistant Intuition\\': \"The Blinger Ultimate Set, Glam Collection, is a hair and fashion accessory kit that allows you to add sparkling gems to your hair, clothing, and accessories. The set includes a Glam Styling Tool and 225 gems in various shapes and colors.\\\\n\\\\nThe components of the set include the Glam Styling Tool, which is a handheld device that you load with gems and click to apply them to your hair or clothing. The set also includes 225 gems, which come in different shapes such as stars, hearts, and circles, and in various colors like pink, blue, green, and silver.\\\\n\\\\nThe materials used in the set include plastic for the Glam Styling Tool and metal and rhinestones for the gems. The gems are made with high-quality materials that are durable and long-lasting.\\\\n\\\\nTo use the Blinger Ultimate Set, you load the gems into the Glam Styling Tool and click the button to apply them to your hair or clothing. The set is designed to be used on any type of hair or fabric, making it a versatile accessory that can be used to add some sparkle and glam to any outfit or hairstyle. The Blinger Ultimate Set is an Amazon Exclusive product, which means that it can only be purchased on Amazon\\'s online store.\"}', additional_kwargs={}), AIMessage(content='Solution: ', additional_kwargs={})]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'atomized_solution' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m problem_statement_file \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39matomized_problem_statement.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m product_description \u001b[39m=\u001b[39m ProductDescription\n\u001b[0;32m----> 4\u001b[0m atomized_problem_solutions \u001b[39m=\u001b[39m atomize_problem_solutions(problem_statement_file, product_description, OPENAI_API_KEY)\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAtomized problem solutions written to atomized_solution_statement.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[115], line 36\u001b[0m, in \u001b[0;36matomize_problem_solutions\u001b[0;34m(problem_statement_file, product_description, openai_api_key)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPrompt: \u001b[39m\u001b[39m\"\u001b[39m, prompt)\n\u001b[1;32m     31\u001b[0m     \u001b[39m# Generate solution using OpenAI API\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[39m# atomized_solution = generate_openai_solution(prompt, chat, chat_prompt)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[39m# print(\"Generated solution:\", atomized_solution)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \n\u001b[1;32m     35\u001b[0m     \u001b[39m# Append problem statement and solution to list\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     atomized_problem_solutions\u001b[39m.\u001b[39mappend((problem_statement, atomized_solution))\n\u001b[1;32m     38\u001b[0m \u001b[39m# Write atomized problem solutions to file\u001b[39;00m\n\u001b[1;32m     39\u001b[0m write_atomized_problem_solution(atomized_problem_solutions)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'atomized_solution' is not defined"
     ]
    }
   ],
   "source": [
    "problem_statement_file = \"atomized_problem_statement.csv\"\n",
    "product_description = ProductDescription\n",
    "\n",
    "atomized_problem_solutions = atomize_problem_solutions(problem_statement_file, product_description, OPENAI_API_KEY)\n",
    "print(\"Atomized problem solutions written to atomized_solution_statement.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "AtomizedSolutions = pd.read_csv('atomized_solution_statement.csv')\n",
    "AtomizedSolutions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oaie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
